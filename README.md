üîí Projet priv√© ‚Äî Ce travail a √©t√© r√©alis√© dans le cadre d‚Äôun projet professionnel encadr√© par [Greta Centre-Val de Loire] pour le compte d‚Äôun partenaire entreprise.

#  √âvaluation Comparative de Mod√®les de Langage Locaux pour Application RAG

##  Contexte

Ce projet s‚Äôinscrit dans le cadre d‚Äôune mission professionnelle en Intelligence Artificielle, visant √† construire une **m√©thodologie d‚Äô√©valuation rigoureuse et automatis√©e** des mod√®les de langage locaux (**LLMs**) pour des cas d‚Äôusage **RAG** (Retrieval-Augmented Generation), le tout dans un environnement **100% local**.

Il int√®gre une approche compl√®te m√™lant **tests, m√©triques, analyses** et **observabilit√©** afin d‚Äôidentifier les mod√®les les plus adapt√©s √† des contextes exigeants dans une logique de respect de la confidentialit√© des donn√©es, de performance locale, de fiabilit√© du raisonnement produit par les mod√®les et de robustesse.

---

##  Objectifs du projet

- D√©finir une **m√©thodologie r√©utilisable** d‚Äô√©valuation de mod√®les LLM
- Mettre en ≈ìuvre un **pipeline automatis√©** : prompts ‚Üí mod√®les ‚Üí √©valuation ‚Üí analyse
- Comparer des LLMs open-source tournant en local (via Ollama / LM Studio)
- G√©n√©rer des **r√©sultats chiffr√©s, interpr√©tables et visualisables**
- √âvaluer la **qualit√© des r√©ponses** produites sur des cas RAG typiques.
- Mesurer les **performances** (temps de r√©ponse, consommation m√©moire, stabilit√©).
- Identifier le mod√®le offrant le **meilleur compromis** pour une int√©gration locale efficace
- Proposer un d√©but de **syst√®me de monitoring** pour le suivi des performances dans le temps.

---
##  √âtapes du pipeline

1.  Pr√©paration des prompts de test (cas r√©alistes RAG)
2.  Ex√©cution automatique des mod√®les sur chaque prompt
3.  Collecte des r√©ponses, temps, usages m√©moire/CPU
4.  √âvaluation qualitative et quantitative (scoring, m√©triques)
5.  Analyse comparative (tableaux, graphiques)
6.  Monitoring : d√©tection d‚Äô√©carts, performances anormales (WIP)

---

## Structure du d√©p√¥t

```

‚îú‚îÄ‚îÄ prompts/                 # Contient les prompts de test (questions types pour RAG)
‚îÇ   ‚îî‚îÄ‚îÄ rag_queries.json
‚îÇ
‚îú‚îÄ‚îÄ scripts/                 # Scripts Python pour ex√©cuter les mod√®les et enregistrer les r√©sultats
‚îÇ   ‚îî‚îÄ‚îÄ run_tests.py
‚îÇ
‚îú‚îÄ‚îÄ results/                 # Donn√©es de sortie (r√©ponses, temps, usage m√©moire, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ model_outputs.csv
‚îÇ
‚îú‚îÄ‚îÄ analysis/                # Notebooks d‚Äôanalyse et visualisations
‚îÇ   ‚îî‚îÄ‚îÄ analysis.ipynb
‚îÇ
‚îú‚îÄ‚îÄ report/                  # Rapport final du projet + support de pr√©sentation
‚îÇ   ‚îî‚îÄ‚îÄ rapport_final.md / .pdf
‚îÇ
‚îú‚îÄ‚îÄ PLAN.md                  # Plan d‚Äôorganisation du projet (planning, √©tapes, m√©triques)
‚îî‚îÄ‚îÄ README.md                # Pr√©sentation g√©n√©rale du projet (ce fichier)
```

---

##  Mod√®les test√©s

Les mod√®les sont ex√©cut√©s **localement** via [Ollama](https://ollama.com/) :

| Mod√®le       | Taille      | Type de licence | Atout principal |
|--------------|-------------|------------------|-----------------|
| Mistral 7B   | L√©ger       | Apache 2.0       | Rapide et pr√©cis |
| LLaMA 3 8B   | Moyen       | Meta (non-commercial) | Tr√®s performant |
| Phi-3 Small  | Tr√®s l√©ger  | MIT              | CPU-friendly |
| Qwen 7B      | Moyen       | Apache 2.0       | Bonne compr√©hension |
| Falcon 7B    | Moyen       | Apache 2.0       | Robuste et open |

---

##  M√©triques d‚Äô√©valuation

Chaque mod√®le est √©valu√© selon plusieurs **crit√®res objectifs** :

-  **Pertinence de la r√©ponse**
-  **Utilisation correcte du contexte**
-  **Temps de g√©n√©ration ou de r√©ponse**
-  **Consommation m√©moire / CPU / GPU**
-  **Verbosit√©**
-  **Robustesse face aux erreurs**
-  **Facilit√© d'int√©gration dans un pipeline RAG**
-  **Observabilit√© (monitoring de coh√©rence)**

---

##  Jeu de donn√©es

Le fichier `prompts/rag_queries.json` contient un ensemble de **questions simul√©es** (entre 15 et 20) repr√©sentant des cas r√©els d‚Äôutilisation RAG :
- Questions simples
- Questions avec raisonnement
- Cas ambigus
- Cas bruit√©s (erreurs dans le contexte)

---

##  Lancement des tests

Les scripts Python permettent de tester automatiquement chaque mod√®le avec les prompts fournis :

```bash
    # Mise en place de l'environnement
    py -3.12 -m venv .venv
    .venv\Scripts\Activate.ps1  # ou activate.bat selon ton terminal
    pip install -r requirements.txt

    # Test des prompts
    python scripts/run_tests.py --model mistral --prompts prompts/rag_queries.json
```
Les r√©sultats sont sauvegard√©s dans le dossier results/.

# Analyse
Les donn√©es collect√©es sont analys√©es dans le notebook analysis/analysis.ipynb via :

- Tableaux comparatifs
- Graphiques radar et / ou en barres
- Matrice de performances (Pour montrer comment chaque mod√®le se comporte en conditions r√©elles (temps, ressources, stabilit√©))
- Matrices de scoring (Pour montrer la valeur des r√©ponses produites (pertinence, logique, robustesse...))

# Rapport
Le rapport final comprend :

- M√©thodologie compl√®te
- D√©tails sur les mod√®les
- R√©sultats bruts et analys√©s
- Recommandations pour l‚Äôint√©gration dans une app RAG
- Pr√©sentation synth√©tique du projet

Disponible dans le dossier /report.

# Auteur
Projet r√©alis√© par [ PatriciaTenda](https://github.com/PatriciaTenda/LLM-Comparatif-RAG/), Dans le cadre de la formation "D√©veloppeuse en Intelligence Artificielle", Greta Centre-Val de Loire ‚Äì 2025.

# Licence & Droits d‚Äôusage
Ce projet a √©t√© r√©alis√© dans le cadre d‚Äôune mission confi√©e par une entreprise partenaire, dans le cadre de ma formation professionnelle en Intelligence Artificielle.
Le contenu de ce d√©p√¥t, y compris les scripts, donn√©es et analyses, est soumis √† des droits r√©serv√©s.
Toute reproduction, diffusion ou utilisation sans autorisation expresse est interdite.
Ce d√©p√¥t est mis √† disposition uniquement √† des fins p√©dagogiques et d‚Äô√©valuation.

# Remerciements
Merci √† l‚Äô√©quipe p√©dagogique, aux d√©veloppeurs des mod√®les open-source, et √† la communaut√© IA qui partage ses outils et connaissances et les rendent accessibles.

